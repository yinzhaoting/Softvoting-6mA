{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4684d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier,GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingCVClassifier,StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgb \n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1cca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sort\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier,GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mlxtend.classifier import StackingCVClassifier,StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import lightgbm as lgb \n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c435c0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义SN、SP、ACC、MCC\n",
    "def sn_sp_acc_mcc(true_label, predict_label, pos_label=1):\n",
    "    import math\n",
    "    pos_num = np.sum(true_label == pos_label)\n",
    "    print('pos_num=', pos_num)\n",
    "    neg_num = true_label.shape[0] - pos_num\n",
    "    print('neg_num=', neg_num)\n",
    "    tp = np.sum((true_label == pos_label) & (predict_label == pos_label))\n",
    "    print('tp=', tp)\n",
    "    tn = np.sum(true_label == predict_label) - tp\n",
    "    print('tn=', tn)\n",
    "    sn = tp / pos_num\n",
    "    sp = tn / neg_num\n",
    "    acc = (tp + tn) / (pos_num + neg_num)\n",
    "    fn = pos_num - tp\n",
    "    fp = neg_num - tn\n",
    "    print('fn=', fn)\n",
    "    print('fp=', fp)\n",
    "\n",
    "    tp = np.array(tp, dtype=np.float64)\n",
    "    tn = np.array(tn, dtype=np.float64)\n",
    "    fp = np.array(fp, dtype=np.float64)\n",
    "    fn = np.array(fn, dtype=np.float64)\n",
    "    mcc = (tp * tn - fp * fn) / (np.sqrt((tp + fn) * (tp + fp) * (tn + fp) * (tn + fn)))\n",
    "    return sn, sp, acc, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d34b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/1_EIIP_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data2=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/2_binary_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data3=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/4_Kmer_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data4=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/5_PseDNC_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "\n",
    "data5=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/3_NCP_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data6=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/6_RCKmer_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data7=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/7_DACC_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data8=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/8_DCC_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data9=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/9_DPCP_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data10=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/10_ANF_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data11=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/11_NAC_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data12=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/12_DAC_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data13=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/13_TACC_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data14=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/14_TAC_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "data15=pd.read_csv(\"/code/jupyter notebook/N6/SoftingVote6mA/15_TCC_data_train.csv\",encoding='gbk',engine='python',header=None)\n",
    "\n",
    "\n",
    "print(data1.shape)\n",
    "print(data2.shape)\n",
    "print(data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cf1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = np.array(data1)\n",
    "data2 = np.array(data2)\n",
    "data3 = np.array(data3)\n",
    "data4 = np.array(data4)\n",
    "\n",
    "data5 = np.array(data5)\n",
    "data6 = np.array(data6)\n",
    "data7 = np.array(data7)\n",
    "data8 = np.array(data8)\n",
    "\n",
    "data9 = np.array(data9)\n",
    "data10 = np.array(data10)\n",
    "data11 = np.array(data11)\n",
    "data12 = np.array(data12)\n",
    "\n",
    "data13 = np.array(data13)\n",
    "data14 = np.array(data14)\n",
    "data15 = np.array(data15)\n",
    "\n",
    "print(type(data1),type(data3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd72c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1_EIIP = np.delete(data1,0,axis=1)\n",
    "feature2_Onehot = np.delete(data2,0,axis=1)\n",
    "feature3_Kmer = np.delete(data3,0,axis=1)\n",
    "feature4_PseDNC = np.delete(data4,0,axis=1)\n",
    "feature5_NCP = np.delete(data5,0,axis=1)\n",
    "feature6_RCKmer = np.delete(data6,0,axis=1)\n",
    "feature7_DACC = np.delete(data7,0,axis=1)\n",
    "feature8_DCC = np.delete(data8,0,axis=1)\n",
    "feature9_DPCP = np.delete(data9,0,axis=1)\n",
    "feature10_ANF = np.delete(data10,0,axis=1)\n",
    "feature11_NAC = np.delete(data11,0,axis=1)\n",
    "feature12_DAC = np.delete(data12,0,axis=1)\n",
    "feature13_TACC = np.delete(data13,0,axis=1)\n",
    "feature14_TAC = np.delete(data14,0,axis=1)\n",
    "feature15_TCC = np.delete(data15,0,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850bfdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "allfeature=np.concatenate((feature1_EIIP,feature2_Onehot,feature3_Kmer,feature4_PseDNC,feature15_TCC),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e967fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from scipy import interp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "LR = LogisticRegression(random_state=100,tol=1e-6)  # 逻辑回归模型\n",
    "SVM = SVC(probability=True,random_state=100,tol=1e-6)  # SVM模型\n",
    "RF = RandomForestClassifier(n_estimators=100,random_state=100) #　随机森林\n",
    "GBDT = GradientBoostingClassifier(random_state=100) #GBDT\n",
    "XGB = XGBClassifier(random_state=100,eval_metric=['logloss','auc','error'])  #XGBoost\n",
    "LGBM = LGBMClassifier(random_state=100)  #LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "\n",
    "\n",
    "# 对其中1折进行预测，对其他折进行训练\n",
    "skfolds = StratifiedKFold(n_splits=5, random_state=0,shuffle=True)\n",
    "test_auc=[]\n",
    "test_result=[]\n",
    "for train_index, test_index in skfolds.split(allfeature, train_y):       \n",
    "    X_train_folds = allfeature[train_index]\n",
    "    y_train_folds = (train_y[train_index])\n",
    "    X_test_fold = allfeature[test_index]\n",
    "    y_test_fold = (train_y[test_index])\n",
    "\n",
    "    \n",
    "    LGBM.fit(X_train_folds, y_train_folds)\n",
    "    # 预测测试集中数据的分类类别\n",
    "    y_pred = LGBM.predict_proba(X_test_fold)[:,1]\n",
    "    pred =y_pred\n",
    "    f = pred>0.5\n",
    "    pred[f]=1\n",
    "    pred[pred<0.6]=0\n",
    "    test_result.append(sn_sp_acc_mcc(y_test_fold,pred,pos_label=1))\n",
    "    FPR,TPR,threshold=roc_curve(y_test_fold,LGBM.predict_proba(X_test_fold)[:,1] ,pos_label=1)\n",
    "    AUC=auc(FPR,TPR)\n",
    "    print(AUC)\n",
    "  \n",
    "    test_auc.append(AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da42c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_result,test_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
